import asyncio
import hashlib
import time
import orjson
import re
import random
import aiohttp
from core.logger import logger
from core.redis_client import redis_client
from core.dependencies import urls, get_headers
from utils.tools import remove_emojis
from settings.config import TEXT_LIST, settings
from fastapi.responses import StreamingResponse
from fastapi import Request
from core.services.v1.tts_server import text2speech
from core.services.v1.llm_server_other import get_next_suggested

logger.debug(f"{__name__} mode: {settings.mode}")

async def chat_messages_(request:Request, text:str, **kwargs):
    logger.debug(f"kwargs: {kwargs}")
    start_time = time.time()
    newline_clean = re.compile(r"[ \n\t\\*]+") # å¤„ç†æ¢è¡Œç¬¦
    headers = get_headers(request).copy()
    api_key = request.state.api_key or settings.api_key
    user_id = kwargs.get('user_id') or request.state.user_id
    redis_key = f"conn:{api_key}:{user_id}"
    next_suggested_key = f"suggested:{api_key}:{user_id}"
    # è·å–ä¸Šä¸€æ¬¡ä¼šè¯ID ä¸å­˜åœ¨æ—¶å€™è¿”å›ç©ºå­—ç¬¦ä¸²
    old_conv_id = await redis_client.get(redis_key) or ""
    data = {
        "query": text,
        "inputs": {},
        "response_mode": "streaming",
        "conversation_id": old_conv_id,
        "user": user_id
    }
    data.update({"query": text})
    full_text_buffer = []
    async with aiohttp.ClientSession() as session:
        async with session.post(urls['chat-messages'], headers=headers, json=data) as response:
            if response.status != 200:
                logger.error(f"LLMæ¥å£å‘ç”Ÿé”™è¯¯,è¯·æ£€æŸ¥. çŠ¶æ€ç : {response.status} {data} {await response.text()}") # TODO åç»­å‘é‚®ä»¶æˆ–è€…å…¶ä»–æ–¹æ¡ˆ
                random_text = random.choice(TEXT_LIST)
                audio_result = await asyncio.create_task(
                    text2speech(request=request, text=random_text, model=settings.mode, kwargs=kwargs)
                )
                result_data = {
                    "event": "llm_error",
                    "url": audio_result["url"],
                    "text": random_text
                }
                yield f"event: tts\ndata: {orjson.dumps(result_data)}\n\n".encode()
                return

            async for raw_line in response.content:
                if await request.is_disconnected():
                    logger.info("å®¢æˆ·ç«¯æ–­å¼€")
                    break
                line = raw_line.decode("utf-8").strip()
                if not line.startswith("data:"):
                    continue
                try:
                    json_data = orjson.loads(line[5:])  # å»æ‰ "data:"
                    # logger.debug(f"{__name__} json_data: {json_data}")
                except Exception as e:
                    logger.warning(f"JSONè§£æå¤±è´¥: {str(e)}")
                    continue
                if json_data['event'] == 'message':
                    answer = json_data.get("answer")
                    if not answer:
                        continue
                    clean_text = await remove_emojis(answer)
                    print(clean_text)
                    clean_text = newline_clean.sub(' ', clean_text).strip()  # æ›¿æ¢æ¢è¡Œç¬¦
                    full_text_buffer.append(clean_text)
            # {'event': 'message_end',
            # 'conversation_id': 'd0a6b05a-fac8-4755-ac79-c712d76dda6f', 'message_id': '9d335ad2-6748-467b-94a2-7cf821a0d752', 'created_at': 1741224569, 'task_id': '8f2698d0-7e8a-4c5b-a30d-ef09dd595185', 'id': '9d335ad2-6748-467b-94a2-7cf821a0d752', 'metadata': {'retriever_resources': [{'dataset_id': '3f24317b-9caa-4eb5-a5b8-886efb465f63', 'dataset_name': 'ç§‘æŠ€é¦†', 'document_id': '866fb8a9-6833-4b55-b389-7bdd89229597', 'document_name': 'é¢„çº¦è´­ç¥¨.docx', 'data_source_type': 'upload_file', 'segment_id': '60c6339a-19c3-4d88-a49b-acf48b4c7ecd', 'retriever_from': 'api', 'score': 0.32974573969841003, 'content': '\nä¸ªäººé¢„çº¦ï¼š\nç‰¹æ•ˆå½±é™¢\næ™®é€šç¥¨ï¼š 30å…ƒ/äºº/åœº\nä¼˜æƒ ç¥¨ï¼š 20å…ƒ/äºº/åœº\nä¼˜æƒ ç¥¨ï¼š æœªæ»¡18å‘¨å²çš„æœªæˆå¹´äººå’Œå…¨æ—¥åˆ¶å¤§å­¦æœ¬ç§‘åŠä»¥ä¸‹å­¦å†å­¦ç”Ÿï¼ˆä¸å«æˆäººæ•™è‚²åŠç ”ç©¶ç”Ÿï¼‰ã€‚\næ¸©é¦¨æç¤ºï¼š\n1.ç‰¹æ•ˆç”µå½±ï¼ˆå·¨å¹•å½±é™¢é™¤å¤–ï¼‰ä¸é€‚å®œå¿ƒè„ç—…ã€é«˜è¡€å‹ç­‰æ‚£è€…åŠå©´å¹¼å„¿è§‚çœ‹ï¼Œè¯·æ…é‡è´­ç¥¨ã€‚\n2.åŠ¨æ„Ÿå½±é™¢è°¢ç»1.2ç±³ä»¥ä¸‹å„¿ç«¥ã€70å‘¨å²ä»¥ä¸Šè€å¹´äººåŠå­•å¦‡å…¥åœºã€‚\n3.4Då½±é™¢è°¢ç»å­•å¦‡å…¥åœºã€‚\n4.ä¼˜æƒ äººç¾¤åœ¨æ£€ç¥¨æ—¶é¡»å‡ºç¤ºè´­ç¥¨ç™»è®°çš„æœ‰æ•ˆè¯ä»¶å’Œå­¦ç”Ÿè¯ã€‚\n5.æ— è¯æˆ–ä¸ç¬¦åˆä¼˜æƒ ç¥¨å’Œå…è´¹ç¥¨èŒƒå›´çš„é¡»è´­æ™®é€šç¥¨ã€‚', 'position': 1}, {'dataset_id': '3f24317b-9caa-4eb5-a5b8-886efb465f63', 'dataset_name': 'ç§‘æŠ€é¦†', 'document_id': '2af21d11-9c06-4ec7-aba8-0b0dd4b3beaa', 'document_name': 'åœºé¦†æ¦‚å†µ.docx', 'data_source_type': 'upload_file', 'segment_id': '64095b7d-cb80-4a94-9db8-d7960a7d09ac', 'retriever_from': 'api', 'score': 0.313749223947525, 'content': '1æ¥¼è®¾æœ‰ï¼šå„¿ç«¥ç§‘å­¦ä¹å›­ã€åå¤ä¹‹å…‰ã€çŸ­æœŸå±•å…ã€çƒå¹•å½±é™¢ã€æŠ¥å‘Šå…åœºæ‰€\n1Fåˆ†å¸ƒå›¾URLï¼šhttp://192.168.2.251:9001/api/v1/buckets/mypic/objects/download?preview=true&prefix=1F.png&version_id=null\n', 'position': 2}, {'dataset_id': '3f24317b-9caa-4eb5-a5b8-886efb465f63', 'dataset_name': 'ç§‘æŠ€é¦†', 'document_id': '2af21d11-9c06-4ec7-aba8-0b0dd4b3beaa', 'document_name': 'åœºé¦†æ¦‚å†µ.docx', 'data_source_type': 'upload_file', 'segment_id': 'ecc25a4e-c6b9-4c17-b842-6549a2906c90', 'retriever_from': 'api', 'score': 0.3135141432285309, 'content': '3æ¥¼è®¾æœ‰ï¼šç§‘æŠ€ä¸ç”Ÿæ´»Aå…ã€ç§‘æŠ€ä¸ç”Ÿæ´»Bå…ã€ç§‘æŠ€ä¸ç”Ÿæ´»Cå…ã€ç§‘æŠ€ä¸ç”Ÿæ´»Då…åœºæ‰€\n3Fåˆ†å¸ƒå›¾URLï¼šhttp://192.168.2.251:9001/api/v1/buckets/mypic/objects/download?preview=true&prefix=3F.png&version_id=null\n', 'position': 3}, {'dataset_id': '3f24317b-9caa-4eb5-a5b8-886efb465f63', 'dataset_name': 'ç§‘æŠ€é¦†', 'document_id': '2af21d11-9c06-4ec7-aba8-0b0dd4b3beaa', 'document_name': 'åœºé¦†æ¦‚å†µ.docx', 'data_source_type': 'upload_file', 'segment_id': '3f9411be-8e78-4369-8138-077d565a66bc', 'retriever_from': 'api', 'score': 0.3129405975341797, 'content': '4æ¥¼è®¾æœ‰ï¼šæŒ‘æˆ˜ä¸æœªæ¥Aå…ã€æŒ‘æˆ˜ä¸æœªæ¥Bå…ã€æŒ‘æˆ˜ä¸æœªæ¥Cå…ã€æŒ‘æˆ˜ä¸æœªæ¥Då…åœºæ‰€\n4Fåˆ†å¸ƒå›¾URLï¼šhttp://192.168.2.251:9001/api/v1/buckets/mypic/objects/download?preview=true&prefix=4F.png&version_id=null\n', 'position': 4}], 'usage': {'prompt_tokens': 1546, 'prompt_unit_price': '0.0', 'prompt_price_unit': '0.0', 'prompt_price': '0.0', 'completion_tokens': 20, 'completion_unit_price': '0.0', 'completion_price_unit': '0.0', 'completion_price': '0.0', 'total_tokens': 1566, 'total_price': '0.0', 'currency': 'USD', 'latency': 1.1669281070062425}}, 'files': None}
            try:
                logger.debug(json_data)
                content = "".join(full_text_buffer)
                logger.debug(full_text_buffer)
                logger.info(f"â³ å¤§æ¨¡å‹è€—æ—¶: {time.time() - start_time:.2f}")
                logger.info(f"ğŸ’¬ å¤§æ¨¡å‹å›å¤: {content}")
                # logger.info("ğŸ’¡ å‡†å¤‡å‘é€æœ€ç»ˆTTSä»»åŠ¡")
                mode = request.state.mode or settings.mode
                logger.debug(f"{__name__} mode: {mode}")
                audio_result = await asyncio.create_task(
                    text2speech(request=request, text=content, model=mode, kwargs=kwargs)
                )
                if message_id := json_data.get("message_id"):
                    logger.debug(f"ç”¨æˆ·: {user_id} æ›´æ–°message_id: {message_id}")
                    await asyncio.create_task(redis_client.setex(
                        name=next_suggested_key,
                        time=settings.cache_expiry,
                        value=message_id
                    ))
                next_suggested = await get_next_suggested(
                    request=request,
                    user_id=user_id,
                    suggested_redis_key=next_suggested_key
                )
                # {'result': 'success', 'data': ['ä½ åƒé¥­äº†å—ï¼Ÿ', 'å“ªé‡Œä¸èˆ’æœï¼Ÿ', 'å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ']}
                result_data = {
                    "event": "tts_completed",
                    "url": audio_result["url"],
                    "text": content,
                    "suggested": next_suggested['data']
                }
                logger.debug(f"{__name__} orjson.dumps(result_data): {orjson.dumps(result_data)}, {type(orjson.dumps(result_data))}")
                # yield f"event: tts\ndata: {orjson.dumps(result_data)}\n\n".encode()
                yield f"event: tts\ndata: {orjson.dumps(result_data).decode('utf-8')}\n\n".encode()
                if new_conv_id := json_data.get('conversation_id'):
                    await asyncio.create_task(redis_client.setex(
                        name=redis_key,
                        time=settings.cache_expiry,
                        value=new_conv_id
                    ))
                    logger.debug(f"ç”¨æˆ·: {user_id} æ›´æ–°ä¼šè¯id: {new_conv_id}")
            except Exception as e:
                logger.error(f"å‡ºé”™äº†: {e}")
                random_text = random.choice(TEXT_LIST)
                audio_result = await asyncio.create_task(
                    text2speech(request=request, text=random_text, model=settings.mode, kwargs=kwargs)
                )
                result_data = {
                    "event": "llm_error",
                    "url": audio_result["url"],
                    "text": random_text
                }
                yield f"event: tts\ndata: {orjson.dumps(result_data)}\n\n".encode()
# ----------------------------------------------------------------------------------------------------------------------
async def chat_message_stream_function(request, text):
    headers = get_headers(request).copy()
    user_id = request.state.user_id
    redis_key = f"conn:{user_id}"
    old_conv_id = await redis_client.get(redis_key) or ""
    data = {
        "inputs": {},
        "query": text,
        "response_mode": "streaming",
        "conversation_id": old_conv_id,
        "user": user_id   # TODO è¿™éƒ¨åˆ†åç»­ä¸èƒ½å†™æ­»
    }
    async with aiohttp.ClientSession() as session:
        async with session.post(urls['chat-messages'], headers=headers, json=data) as response:
            if response.status != 200:
                logger.error(f"LLMæ¥å£å‘ç”Ÿé”™è¯¯,è¯·æ£€æŸ¥. çŠ¶æ€ç : {response.status}")  # TODO åç»­å‘é‚®ä»¶æˆ–è€…å…¶ä»–æ–¹æ¡ˆ
                event = {
                    "event": "error",
                    "message": random.choice(TEXT_LIST)
                }
                event.update({"code": response.status,"params": data})
                yield f"event: error\ndata: {orjson.dumps(event)}\n\n"
                return
            async for raw_line in response.content:
                yield raw_line
                if await request.is_disconnected():
                    logger.info("å®¢æˆ·ç«¯æ–­å¼€")
                    break
                line = raw_line.decode("utf-8").strip()
                if not line.startswith("data:"):
                    continue
                try:
                    json_data = orjson.loads(line[5:])  # å»æ‰ "data:"
                    if new_conv_id := json_data.get('conversation_id'):
                        asyncio.create_task(redis_client.setex(
                            name=redis_key,
                            time=settings.cache_expiry,
                            value=new_conv_id
                        ))
                        logger.debug(f"ç”¨æˆ·: {user_id} æ›´æ–°ä¼šè¯id: {new_conv_id}")
                except Exception as e:
                    logger.warning(f"JSONè§£æå¤±è´¥: {str(e)}")
                    event = {
                        "event": "error",
                        "message": random.choice(TEXT_LIST)
                    }
                    event.update({"code": response.status, "params": data})
                    yield f"event: error\ndata: {orjson.dumps(event)}\n\n"
# æµå¼SSR
async def chat_message_stream_(request, text:str):
    ssr_headers = {
        "Cache-Control": "no-cache",
        "Connection": "Keep-alive",
        "X-Accel-Buffering": "no"
    }
    return StreamingResponse(
        chat_message_stream_function(request, text),
        media_type="text/event-stream",
        headers=ssr_headers
    )
# ----------------------------------------------------------------------------------------------------------------------

# å¤„ç†ç»“æœå†…å®¹
async def collect_tts_results(request, text, **kwargs):
    start_time = time.time()
    # æ–°å¢ç¼“å­˜æ£€æŸ¥ TODO è¿™é‡Œæœ‰bug ä¸è¿‡å…ˆä¸ä¿®
    reference_id = kwargs.get('reference_id') or request.state.reference_id
    user_id = kwargs.get("user_id") or request.state.user_id
    text_sha256 = hashlib.sha256(f"{text}_{reference_id}".encode("utf-8")).hexdigest()
    llm_redis_key = f"llm:{user_id}:{reference_id}:{text_sha256}"
    is_cached = await redis_client.get(llm_redis_key)
    if is_cached:
        logger.info(f"ğŸ¯ å‘½ä¸­LLMç¼“å­˜(key: {text_sha256[:10]})")
        total_time = time.time() - start_time
        data = await redis_client.getex(llm_redis_key)
        json_data = orjson.loads(data)
        json_data.update({"total_time": total_time})
        return json_data


    data_dict = dict()
    start_time = time.time()

    async for chunk in chat_messages_(request, text, **kwargs):
        # logger.info(f"ğŸš¦ åŸå§‹æ•°æ®å—ç±»å‹: {type(chunk)} | å†…å®¹ç‰‡æ®µ: {chunk[:100]}...")
        try:
            # å°è¯•è§£æSSEæ ¼å¼
            decoded:str = chunk.decode().strip()
            if decoded.startswith("event:"):
                event_type = decoded.split('\n')[0].split(': ')[1]
                json_str = decoded.split('\ndata: ')[1]
                logger.debug(f"{__name__} json_str: {json_str} {type(json_str)} ")
                data = orjson.loads(json_str.encode("utf-8"))
                logger.debug(f"{__name__} data: {data} {type(data)} ")
                if event_type == "tts":
                    # logger.info(f"ğŸ”Š æ•è·åˆ°LLMæ–‡æœ¬: {data['text']}")
                    # logger.info(f"ğŸ”Š æ•è·åˆ°TTSäº‹ä»¶: {data['url']}")
                    logger.debug(f"{__name__} data: {data}")
                    # url_list.append(data.pop('url'))
                    data_dict.update(data)
                    data_dict.update({"question": text})
                    logger.debug(f"{__name__} data: {data}")
                    # æ”¾å…¥ç¼“å­˜
                    asyncio.create_task(redis_client.setex(
                        llm_redis_key,
                        settings.cache_expiry,
                        # orjson.dumps({"url_list": url_list, "answer": answer})
                        orjson.dumps(data).decode("utf-8")
                    ))
                    logger.info(f"ğŸ’¾ æ–°å¢LLMç¼“å­˜(å“ˆå¸Œ: {text_sha256[:10]})")
        except Exception as e:
            logger.error(f"âš ï¸ æ•°æ®è§£æå¼‚å¸¸: {str(e)}")
            continue

    total_time = time.time() - start_time
    # return {"total_time": , "url_list": , "answer": }
    data_dict.update({"total_time": total_time})
    logger.debug(f"{__name__} data_dict: {data_dict}")
    return data_dict
