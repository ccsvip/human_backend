import aiohttp
import asyncio
import edge_tts
import aiofiles
import functools
import tempfile
import subprocess
import hashlib
from pathlib import Path
import concurrent.futures
from pydub import AudioSegment
from io import BytesIO
from settings.config import AUDIO_DIR

from core.dependencies import urls
from settings.config import settings
from core.logger import logger
from core.decorators.async_tools import async_timer
from core.redis_client import redis_client
import functools

# è¿æ¥è¶…æ—¶é…ç½®
TTS_CONNECTION_TIMEOUT = aiohttp.ClientTimeout(
    total=15,      # æ€»è¶…æ—¶æ—¶é—´
    connect=3,     # è¿æ¥è¶…æ—¶æ—¶é—´
    sock_read=5,   # è¯»å–è¶…æ—¶æ—¶é—´
    sock_connect=3 # socketè¿æ¥è¶…æ—¶
)

# å…¨å±€TTSè¿æ¥å™¨å’Œä¼šè¯ï¼Œç”¨äºè¿æ¥æ± å¤ç”¨
_tts_connector = None
_tts_session = None

def get_tts_connector():
    """è·å–TTSä¸“ç”¨è¿æ¥å™¨ï¼Œç”¨äºè¿æ¥æ± ä¼˜åŒ–"""
    global _tts_connector
    if _tts_connector is None or _tts_connector.closed:
        _tts_connector = aiohttp.TCPConnector(
            limit=50,  # TTSä¸“ç”¨è¿æ¥æ± 
            limit_per_host=20,  # æ¯ä¸ªTTSä¸»æœºçš„è¿æ¥æ•°
            ttl_dns_cache=300,
            use_dns_cache=True,
            enable_cleanup_closed=True,
            keepalive_timeout=60,  # ä¿æŒè¿æ¥60ç§’
        )
    return _tts_connector

async def get_tts_session():
    """è·å–TTSä¸“ç”¨ä¼šè¯ï¼Œé¿å…é‡å¤åˆ›å»ºClientSessionçš„å¼€é”€"""
    global _tts_session
    if _tts_session is None or _tts_session.closed:
        _tts_session = aiohttp.ClientSession(
            connector=get_tts_connector(),
            timeout=TTS_CONNECTION_TIMEOUT
        )
    return _tts_session

async def cleanup_tts_session():
    """æ¸…ç†TTSä¼šè¯èµ„æº"""
    global _tts_session, _tts_connector
    if _tts_session and not _tts_session.closed:
        await _tts_session.close()
        _tts_session = None
    if _tts_connector and not _tts_connector.closed:
        await _tts_connector.close()
        _tts_connector = None



# å»ºç«‹å±€éƒ¨çº¿ç¨‹æ± ï¼ˆæœ€å¤šå¹¶å‘ 8 ä¸ªéŸ³é¢‘å¤„ç†ä»»åŠ¡ï¼‰
TTS_THREAD_POOL = concurrent.futures.ThreadPoolExecutor(max_workers=8)

async def save_audio_to_db(kwargs, text, file_name, tts_start_time):
    """å¼‚æ­¥ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ•°æ®åº“ï¼Œä¸é˜»å¡ä¸»æµç¨‹"""
    try:
        from api_versions.v2.models import AudioData
        from datetime import datetime
        
        user_question = kwargs.get('user_question', text[:100] + '...' if len(text) > 100 else text)
        ai_response_text = kwargs.get('ai_response_text', text)
        tts_started_at = kwargs.get('tts_started_at', tts_start_time)
        
        await AudioData.create(
            user_question=user_question,
            ai_response_text=ai_response_text,
            audio_file_path=f"static/{file_name}",
            tts_started_at=tts_started_at,
            tts_completed_at=datetime.now()
        )
    except Exception as e:
        logger.warning(f"ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")

@async_timer
async def text_to_audio_old(*, request, text, **kwargs):
    from utils.tools import get_file_name
    from datetime import datetime
    
    # è®°å½•TTSå¼€å§‹æ—¶é—´
    tts_start_time = datetime.now()
    kwargs['tts_started_at'] = tts_start_time

    reference_id = kwargs.get('reference_id') or request.state.reference_id

    # å¯é€‰ï¼šæ„é€ ç¼“å­˜ keyï¼ˆå»ºè®®ç”¨äºåç»­ Redis ç¼“å­˜ï¼‰
    # cache_key = f"tts_cache:{reference_id}:{hashlib.md5(text.encode()).hexdigest()}"
    # cached_url = await redis_client.get(cache_key)
    # if cached_url:
    #     return cached_url.decode()

    data = {
        "text": text,
        "reference_id": reference_id or settings.reference_id,
        "seed": 42,
        "normalize": True,
        "chunk_length": 100,
        "temperature": 0.6,
        "top_p": 0.8,
        "prosody": {"speed": 2.0}
    }

    logger.debug(f"{__name__} data: {data}")

    session = await get_tts_session()
    async with session.post(url=urls['text-to-audio'], json=data) as resp:
        audio_bytes = await resp.read()

    loop = asyncio.get_event_loop()

    try:
        audio_segment = await loop.run_in_executor(
            TTS_THREAD_POOL,
            functools.partial(AudioSegment.from_wav, BytesIO(audio_bytes))
        )
    except Exception as e:
        raise ValueError(f"éŸ³é¢‘è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥APIè¿”å›æ•°æ®æ ¼å¼ : [{text}]") from e

    buffer = BytesIO()
    await loop.run_in_executor(
        TTS_THREAD_POOL,
        functools.partial(
            audio_segment.export,
            buffer,
            format="wav",
            codec="pcm_s16le",
            parameters=["-ar", "16000", "-ac", "1"]
        )
    )
    buffer.seek(0)

    file_name = f"{get_file_name()}.wav"
    async with aiofiles.open(AUDIO_DIR / file_name, "wb") as f:
        await f.write(buffer.read())

    url = request.url_for("audio_files", path=file_name)

    # å¯é€‰ï¼šè®¾ç½®ç¼“å­˜
    # await redis_client.setex(cache_key, settings.cache_expiry, str(url))

    # è‡ªåŠ¨ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ•°æ®åº“
    try:
        from api_versions.v2.models import AudioData
        from datetime import datetime
        
        # ä»è¯·æ±‚çŠ¶æ€æˆ–kwargsä¸­è·å–ç”¨æˆ·é—®é¢˜å’ŒAIå›å¤
        user_question = kwargs.get('user_question', text[:100] + '...' if len(text) > 100 else text)
        ai_response_text = kwargs.get('ai_response_text', text)
        tts_started_at = kwargs.get('tts_started_at', datetime.now())
        
        await AudioData.create(
            user_question=user_question,
            ai_response_text=ai_response_text,
            audio_file_path=f"static/{file_name}",
            tts_started_at=tts_started_at,
            tts_completed_at=datetime.now()
        )
        # logger.info(f"éŸ³é¢‘æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {file_name}")
    except Exception as e:
        logger.warning(f"ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")

    return str(url)

async def text_to_audio_(*, request, text, **kwargs):
    # ç”Ÿæˆç¼“å­˜key
    reference_id = kwargs.get('reference_id') or request.state.reference_id
    tts_speed = request.state.tts_speed or settings.local_tts_speed
    cache_key = f"tts_cache:{hashlib.md5(f'{text}_{reference_id}_{tts_speed}'.encode()).hexdigest()}"
    
    # æ£€æŸ¥ç¼“å­˜
    try:
        cached_result = await redis_client.get(cache_key)
        if cached_result:
            logger.debug(f"TTSç¼“å­˜å‘½ä¸­: {cache_key}")
            return {"url": cached_result}
    except Exception as e:
        logger.warning(f"è¯»å–TTSç¼“å­˜å¤±è´¥: {e}")
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒTTSç”Ÿæˆ
    url = await text_to_audio_ffmpeg_speed(request=request, text=text, **kwargs)
    if not url:
        data = {"url": ""}
    else:
        data = {"url": str(url)}
        # å­˜å‚¨åˆ°ç¼“å­˜
        try:
            await redis_client.setex(cache_key, settings.cache_expiry, str(url))
            logger.debug(f"TTSç»“æœå·²ç¼“å­˜: {cache_key}")
        except Exception as e:
            logger.warning(f"å­˜å‚¨TTSç¼“å­˜å¤±è´¥: {e}")
    
    return data

async def text_to_audio_aliyun(*, request, text, voice="longxiaochun", **kwargs):
    from utils.tools import get_file_name

    """
    é˜¿é‡Œäº‘è¯­éŸ³åˆæˆ
    """
    import dashscope
    from dashscope.audio.tts_v2 import SpeechSynthesizer
    import tempfile
    
    reference_id = kwargs.get('reference_id') or request.state.reference_id
    if reference_id.lower() == "man":
        voice = "longxiang"
    else:
        voice = "longxiaochun"

    # è‹¥æ²¡æœ‰å°†API Keyé…ç½®åˆ°ç¯å¢ƒå˜é‡ä¸­ï¼Œéœ€å°†ä¸‹é¢è¿™è¡Œä»£ç æ³¨é‡Šæ”¾å¼€ï¼Œå¹¶å°†apiKeyæ›¿æ¢ä¸ºè‡ªå·±çš„API Key
    dashscope.api_key = settings.dashscope_api_key
    model = "cosyvoice-v1"
    synthesizer = SpeechSynthesizer(model=model, voice=voice)
    audio = synthesizer.call(text)
    print('requestId: ', synthesizer.get_last_request_id())

    # é¦–å…ˆå°†è·å–çš„éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
        temp_file.write(audio)
        temp_file_path = temp_file.name
    
    # ç„¶åä½¿ç”¨pydubä»æ–‡ä»¶åŠ è½½éŸ³é¢‘ï¼ˆè®©pydubè‡ªåŠ¨æ£€æµ‹æ ¼å¼ï¼‰
    audio_segment = AudioSegment.from_file(temp_file_path)
    # è½¬æ¢ä¸º16kHzå•å£°é“
    audio_segment = audio_segment.set_frame_rate(16000).set_channels(1)
    
    buffer = BytesIO()
    audio_segment.export(
        buffer,
        format="wav",
        codec="pcm_s16le",
        parameters=["-ar", "16000", "-ac", "1"]
    )
    buffer.seek(0)
    
    file_name = f"{get_file_name()}.wav"
    async with aiofiles.open(AUDIO_DIR / file_name, 'wb') as f:
        await f.write(buffer.read())
        url = request.url_for("audio_files", path=file_name)
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        import os
        os.unlink(temp_file_path)
        return str(url)

async def text_to_audio_qwen(*, request, text, **kwargs):
    """
    é€šè¿‡dashscopeè°ƒç”¨qwen-tts
    """
    import os
    import requests
    import dashscope
    from utils.tools import get_file_name

    reference_id = kwargs.get('reference_id') or request.state.reference_id
    if reference_id.lower() == "woman":
        voice = "Cherry"
    else:
        voice = "Ethan"

    response = dashscope.audio.qwen_tts.SpeechSynthesizer.call(
        model="qwen-tts",
        api_key=settings.dashscope_api_key,
        text=text,
        voice=voice
    )

    return response.output.audio["url"]

    # logger.info(type(response))
    # logger.info(response)
    # logger.info("\n")

    # audio_url = response.output.audio["url"]
    # file_name = f"{get_file_name()}.wav"
    # save_path = AUDIO_DIR / file_name

    # try:
    #     response = requests.get(audio_url)
    #     response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
    #     with open(save_path, 'wb') as f:
    #         f.write(response.content)
    #         url = request.url_for("audio_files", path=file_name)
    #         return str(url)
    #     print(f"éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{save_path}")
    # except Exception as e:
    #     print(f"ä¸‹è½½å¤±è´¥ï¼š{str(e)}")

async def text_to_audio_ffmpeg_speed(*, request, text, **kwargs):
    from utils.tools import get_file_name, remove_emojis
    from datetime import datetime
    import time

    # æ€»è®¡æ—¶å¼€å§‹
    total_start_time = time.time()
    
    text = await remove_emojis(text)
    if len(text) < 1:
        return None
    
    text = " ".join(text.split())
    text = text.replace("æˆäºº", "æ™¨äºº")
    # äºŒæ¬¡åˆ¤ç©ºï¼šå»é™¤ç©ºç™½åä¸ºç©ºåˆ™ç›´æ¥è·³è¿‡ï¼Œé¿å…ç©ºéŸ³é¢‘è¿›å…¥åç»­æµç¨‹
    if not text:
        logger.warning("TTSæ–‡æœ¬æ¸…ç†åä¸ºç©ºï¼Œå·²è·³è¿‡æœ¬æ¬¡ç”Ÿæˆ")
        return None
    logger.debug(f"to tts -> {text}")
    
    # è®°å½•TTSå¼€å§‹æ—¶é—´
    tts_start_time = datetime.now()
    kwargs['tts_started_at'] = tts_start_time

    reference_id = kwargs.get('reference_id') or request.state.reference_id
    prosody_speed = request.state.tts_speed or settings.local_tts_speed  # é»˜è®¤è¯­é€Ÿå€é€Ÿ

    data = {
        "text": text,
        "reference_id": reference_id or settings.reference_id,
        "seed": 42,
        "normalize": True,
        "chunk_length": 100,
        "temperature": 0.6,
        "top_p": 0.8
    }

    logger.debug(f"{__name__} data: {data}")
    
    # TTS APIè°ƒç”¨è®¡æ—¶
    api_start_time = time.time()
    logger.info(f"ğŸ™ï¸ å¼€å§‹è°ƒç”¨TTS APIï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}ï¼Œè¯­é€Ÿ: {prosody_speed}x")

    # è¯·æ±‚ TTS æ¥å£ - ä½¿ç”¨ä¸“ç”¨ä¼šè¯ä¼˜åŒ–
    session = await get_tts_session()
    async with session.post(url=urls['text-to-audio'], json=data) as resp:
        audio_bytes = await resp.read()
    # æ ¡éªŒTTS APIè¿”å›éŸ³é¢‘æœ‰æ•ˆæ€§ï¼Œé¿å…ç©ºè¾“å…¥å¯¼è‡´FFmpegæ— è¾“å‡ºæ–‡ä»¶
    if not audio_bytes or len(audio_bytes) == 0:
        logger.warning("TTS API è¿”å›ç©ºéŸ³é¢‘æ•°æ®ï¼Œå·²è·³è¿‡æœ¬æ¬¡ç”Ÿæˆ")
        return None
    
    api_elapsed = time.time() - api_start_time
    logger.info(f"ğŸ™ï¸ TTS APIè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {api_elapsed:.2f}ç§’")

    loop = asyncio.get_event_loop()

    # ä¸ºäº†ç¡®ä¿æ•°å­—äººå˜´å‹åŒæ­¥ï¼Œæ‰€æœ‰æ–‡æœ¬éƒ½å¿…é¡»ç»è¿‡ç›¸åŒçš„FFmpegå¤„ç†æµç¨‹
    # ä¿æŒä¸€è‡´çš„è¯­é€Ÿå’ŒéŸ³é¢‘ç‰¹æ€§

    input_path = None
    output_path = None
    try:
        # FFmpegå¤„ç†è®¡æ—¶
        ffmpeg_start_time = time.time()
        logger.info(f"ğŸ”§ å¼€å§‹FFmpegéŸ³é¢‘å¤„ç†...")
        
        # å†™å…¥åŸå§‹éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_input:
            temp_input.write(audio_bytes)
            input_path = Path(temp_input.name)

        output_path = input_path.with_name(input_path.stem + "_fast.wav")

        # FFmpeg å‘½ä»¤ï¼šå˜é€Ÿã€è½¬é‡‡æ ·ã€å•å£°é“ï¼Œä¼˜åŒ–å‚æ•°
        cmd = [
            "ffmpeg", "-y",
            "-loglevel", "quiet",
            "-i", str(input_path),
            "-filter:a", f"atempo={prosody_speed}",
            "-ar", "16000",
            "-ac", "1",
            "-f", "wav",  # æ˜ç¡®æŒ‡å®šæ ¼å¼
            "-acodec", "pcm_s16le",  # æ˜ç¡®æŒ‡å®šç¼–è§£ç å™¨
            str(output_path)
        ]

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ FFmpegï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰ï¼Œå¹¶æ£€æŸ¥è¿”å›ç ä¸è¾“å‡ºæ–‡ä»¶
        def _run_ffmpeg():
            return subprocess.run(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                text=True
            )
        result = await loop.run_in_executor(TTS_THREAD_POOL, _run_ffmpeg)
        ffmpeg_elapsed = time.time() - ffmpeg_start_time
        if result.returncode != 0 or not output_path.exists():
            err = (result.stderr or "").strip()
            raise RuntimeError(f"FFmpeg å¤„ç†å¤±è´¥ï¼Œcode={result.returncode}ï¼Œè¾“å‡ºä¸å­˜åœ¨ï¼š{output_path}. {err}")
        logger.info(f"ğŸ”§ FFmpegå¤„ç†å®Œæˆï¼Œè€—æ—¶: {ffmpeg_elapsed:.2f}ç§’")

        # æ–‡ä»¶I/Oè®¡æ—¶
        io_start_time = time.time()
        
        # è¯»å–å˜é€Ÿå¤„ç†åçš„éŸ³é¢‘
        buffer = BytesIO(output_path.read_bytes())

        # ä¿å­˜æœ€ç»ˆéŸ³é¢‘åˆ°æœ¬åœ°
        file_name = f"{get_file_name()}.wav"
        async with aiofiles.open(AUDIO_DIR / file_name, "wb") as f:
            await f.write(buffer.read())

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if input_path:
            input_path.unlink(missing_ok=True)
        if output_path:
            output_path.unlink(missing_ok=True)
        
        io_elapsed = time.time() - io_start_time
        logger.info(f"ğŸ’¾ æ–‡ä»¶I/Oå®Œæˆï¼Œè€—æ—¶: {io_elapsed:.2f}ç§’")

        url = request.url_for("audio_files", path=file_name)
        
        # æ•°æ®åº“ä¿å­˜ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡è¿”å›ï¼‰
        asyncio.create_task(save_audio_to_db(kwargs, text, file_name, tts_start_time))
        
        total_elapsed = time.time() - total_start_time
        logger.info(f"ğŸµ TTSæ€»è€—æ—¶: {total_elapsed:.2f}ç§’ (API: {api_elapsed:.2f}s, FFmpeg: {ffmpeg_elapsed:.2f}s, I/O: {io_elapsed:.2f}s)")
        
        return str(url)

    except Exception as e:
        logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥ï¼ˆFFmpegï¼‰ï¼š[{text}]")
        logger.error(f"é”™è¯¯ä¿¡æ¯: {e}")
        return None
    finally:
        # å…œåº•æ¸…ç†ï¼ˆé˜²æ­¢å¼‚å¸¸æå‰è¿”å›å¯¼è‡´ä¸´æ—¶æ–‡ä»¶æ®‹ç•™ï¼‰
        try:
            if input_path and input_path.exists():
                input_path.unlink(missing_ok=True)
        except Exception:
            pass
        try:
            if output_path and output_path.exists():
                output_path.unlink(missing_ok=True)
        except Exception:
            pass

async def text_to_audio_edge(*, request, text: str, **kwargs):
    from utils.tools import get_file_name
    from datetime import datetime
    import os
    
    # è®°å½•TTSå¼€å§‹æ—¶é—´
    tts_start_time = datetime.now()
    kwargs['tts_started_at'] = tts_start_time

    """å¾®è½¯edge_tts"""
    # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„å­—ç¬¦
    clean_text = text.strip()
    if not clean_text:
        logger.warning("TTSæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
        return None
        
    # ç§»é™¤ä¸€äº›å¯èƒ½å¯¼è‡´Edge TTSé—®é¢˜çš„å­—ç¬¦
    import re
    clean_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', clean_text)
    clean_text = clean_text.replace('\n', ' ').replace('\r', ' ')
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    
    if not clean_text:
        logger.warning("TTSæ–‡æœ¬æ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡")
        return None
    
    # é…ç½®å‚æ•°å¤„ç†
    reference_id = kwargs.get('reference_id') or request.state.reference_id
    voice = settings.voice_name_man if reference_id.lower() == "man" else settings.voice_name_woman
    rate = kwargs.get("rate") or settings.rate

    try:
        # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶
        communicate = edge_tts.Communicate(text=clean_text, voice=voice, rate=rate)
        file_stem = get_file_name()
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¤„ç†æ–‡ä»¶
        async with aiofiles.tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_mp3:
            await communicate.save(tmp_mp3.name)
            
            # éŸ³é¢‘æ ¼å¼è½¬æ¢
            audio = AudioSegment.from_file(tmp_mp3.name)
            audio = audio.set_channels(1).set_frame_rate(16000).set_sample_width(2)
            
            # ä¿å­˜æœ€ç»ˆæ–‡ä»¶
            wav_path = AUDIO_DIR / f"{file_stem}.wav"
            audio.export(wav_path, format="wav")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(tmp_mp3.name)
            except:
                pass
                
    except Exception as e:
        logger.error(f"Edge TTSå¤±è´¥: {e}, æ–‡æœ¬: {clean_text[:50]}...")
        return None

    # è‡ªåŠ¨ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ•°æ®åº“
    try:
        from api_versions.v2.models import AudioData
        from datetime import datetime
        
        user_question = kwargs.get('user_question', text[:100] + '...' if len(text) > 100 else text)
        ai_response_text = kwargs.get('ai_response_text', text)
        tts_started_at = kwargs.get('tts_started_at', datetime.now())
        
        await AudioData.create(
            user_question=user_question,
            ai_response_text=ai_response_text,
            audio_file_path=f"static/{wav_path.name}",
            tts_started_at=tts_started_at,
            tts_completed_at=datetime.now()
        )
        # logger.info(f"éŸ³é¢‘æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {wav_path.name}")
    except Exception as e:
        logger.warning(f"ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")

    # è¿”å›URL
    return str(request.url_for("audio_files", path=wav_path.name))

